---
title: "lasr"
author: "Donny Keighley"
date: "1/1/2021"
output: github_document
---

[lasr](https://github.com/donald-keighley/lasr) is a package designed for reading [Log Ascii Standard (LAS)](https://www.cwls.org/products/) files in R and compiling the data into tables.  Currently it is in the beta testing stages.  Recently it was modified to more fully support LAS 3.0.

## Goals

lasr is primarily designed to help build large log data tables for use in non-standard workflows.  It is optimized for speed.  To accomplish this, most of it is written in C++ and connected to R with [Rcpp](http://www.rcpp.org/).

Ultimately, functions to standardize the log curves for a well will be added including:

* Aliasing
* Depth Merging
* Unit Standardizing
* Matrix Identification
* Writing LAS files

[**lasr**](https://github.com/donald-keighley/lasr) is not designed to accomplish traditional petrophysical workflows and there are no plans to do so. Also, while efforts will be made to handle some non-standard and erroneous LAS files, the goal is not to handle every edge case perfectly.  Rather, files that produce errors will produce the most helpful error messages possible so that bad files can be checked and fixed.  If these are your goals, you should check out the excellent python packages [**lasio**](https://lasio.readthedocs.io/en/latest/index.html) and [**welly**](https://welly.readthedocs.io/en/latest/api/welly.html).

## Installation

You can install [**lasr**](https://github.com/donald-keighley/lasr) from github using the [*install_github*](https://www.rdocumentation.org/packages/devtools/versions/1.13.6/topics/install_github) function from the [devtools](https://devtools.r-lib.org/) package.

```{r install lasr, eval=FALSE}
if (!require('devtools')) install.packages('devtools')
library(devtools)
install_github('https://github.com/donald-keighley/lasr')
```

Currently, the only function is read.las which will import a vector of LAS file paths into a multi-part list.  Each section of the file is now stored as a separate element.  In order to accomodate LAS 3.0 files which may have multiple log data sections, the log parameter, log definition, and log data are combined into one element called a "curveset".  If your vector of paths contains more than one file, the output will be a list of the aformentioned lists.

Here is an example reading a single LAS file that is included with the package:

```{r readlas, eval=TRUE, message=FALSE}
library(lasr)
las = read.las(system.file("extdata", "Jonah_Federal_20-5.las", package = "lasr"))

#Display the WELL section
head(las$WELL, 10)

#Display the log curves
head(las$CURVESETS$CURVESET_1$LOG_DATA, 10)
```

## Speed Test

Since the purpose of this package is to load LAS files as quickly as possible, a speed test is included here with a comparison to python's [**lasio**](https://lasio.readthedocs.io/en/latest/index.html).  First, download a test dataset from the KGS website.  In this case we're using the [2016 logs](http://www.kgs.ku.edu/PRS/Scans/Log_Summary/2016.zip) data.  Download and unzip them into a folder called *"C:/temp/logs"*, or modify the code for wherever you put it.

Next, import the first 500 files.  We'll use 4 threads for this comparison, although if you have more cores you can increase the number of threads to speed it up further.  Only use this option if you are importing more than a handful of files, otherwise the parallel overhead will slow it down.

```{r, import_kgs_logs, eval=TRUE}
files = list.files('C:/temp/logs', pattern = '.las?', full.names=TRUE)
start.time = Sys.time()
las = read.las(files[1:500],nthreads=4)
end.time = Sys.time()
time.taken = end.time - start.time
time.taken
```

Now in Python in parallel using 4 cores:

```{r setup, include=FALSE}
library(reticulate)
use_python("C:/Users/donal/anaconda3")
```

```{python import_kgs_logs_lasio, eval=FALSE}
import lasio, glob, datetime, multiprocessing
from joblib import Parallel, delayed

num_cores = 4
files = glob.glob('C:/temp/logs/*.las')
start_time = datetime.datetime.now()
if __name__ == "__main__":
    las = Parallel(n_jobs=num_cores)(delayed(lasio.read)(file) for file in files[0:499])
end_time = datetime.datetime.now()
print('Duration: {}'.format(end_time - start_time))
```
```{python print_time_python, echo=FALSE}
print('Duration: 0:04:32.132885')
```

## Future work

Currently, the focus is on testing with as many files as possible in order to find and fix bugs and add error messages.  In terms of functionality, writing a function to export LAS files will probably be next.  Adding additional functions to parse some of the other LAS 3.0 sections like Core and Tops is high on the list as well.